{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8B646uCt9Dhy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "import random\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Utilities**"
      ],
      "metadata": {
        "id": "_n2FkKRL4v6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(loss_history):\n",
        "    \"\"\"Plots the training loss over epochs.\"\"\"\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(range(1, len(loss_history) + 1), loss_history, marker='o', linestyle='-')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Average Loss\")\n",
        "    plt.title(\"Training Loss Over Epochs\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (tensor): Input image data.\n",
        "            labels (tensor): Corresponding labels.\n",
        "            transform (callable, optional): Optional transform to be applied on a sample.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "def get_data_loader(batch_size=32):\n",
        "    # Define transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5),  # 50% chance of horizontal flip\n",
        "        transforms.RandomRotation(degrees=(-10, 10)),  # Random rotation between -10 to 10 degrees\n",
        "        transforms.ToTensor()  # Convert images to tensors\n",
        "    ])\n",
        "\n",
        "    # Example: Generate random tensor data (Replace with actual dataset)\n",
        "    num_samples = 1000  # Modify based on dataset size\n",
        "    image_size = (3, 197, 135)  # Example size (C, H, W)\n",
        "\n",
        "    random_data = torch.rand(num_samples, *image_size)  # Fake image data\n",
        "    random_labels = torch.randint(0, 5, (num_samples,))  # Fake labels (5 classes)\n",
        "\n",
        "    dataset = CustomDataset(random_data, random_labels, transform=transform)\n",
        "\n",
        "    # Create DataLoader\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    return data_loader"
      ],
      "metadata": {
        "id": "pN6SRNLK41mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implement Model**\n"
      ],
      "metadata": {
        "id": "StENAMiZ1zGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initial standard convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1)\n",
        "\n",
        "        # Dilated convolutional layers\n",
        "        self.dilated3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, dilation=(3, 2), padding=2)\n",
        "        self.dilated4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, dilation=(6, 4), padding=4)\n",
        "        self.dilated5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, dilation=(12, 8), padding=8)\n",
        "        self.dilated6 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, dilation=(24, 16), padding=16)\n",
        "        self.dilated7 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, dilation=(48, 32), padding=32)\n",
        "\n",
        "        # Concatenation will be handled in forward pass\n",
        "        self.conv9 = nn.Conv2d(in_channels=160, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.conv10 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1)\n",
        "        self.conv11 = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial conv layers\n",
        "        x1 = F.relu(self.conv1(x))\n",
        "        x2 = F.relu(self.conv2(x1))\n",
        "\n",
        "        # Dilated convolutions\n",
        "        d3 = F.relu(self.dilated3(x2))\n",
        "        d4 = F.relu(self.dilated4(d3))\n",
        "        d5 = F.relu(self.dilated5(d4))\n",
        "        d6 = F.relu(self.dilated6(d5))\n",
        "        d7 = F.relu(self.dilated7(d6))\n",
        "\n",
        "        # Concatenation of layer 2 and layer 7\n",
        "        concat = torch.cat((x2, d7), dim=1)\n",
        "\n",
        "        # Final convolutions\n",
        "        x9 = F.relu(self.conv9(concat))\n",
        "        x10 = F.relu(self.conv10(x9))\n",
        "        x11 = self.conv11(x10)  # No activation as it's typically used for logits\n",
        "\n",
        "        return x11\n",
        "\n",
        "# Create model\n",
        "model = CNN()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g94fX-Nf1ytr",
        "outputId": "24e0e48e-16d4-4af9-8d62-239527f70d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (dilated3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(3, 2))\n",
            "  (dilated4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(6, 4))\n",
            "  (dilated5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(12, 8))\n",
            "  (dilated6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(24, 16))\n",
            "  (dilated7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(32, 32), dilation=(48, 32))\n",
            "  (conv9): Conv2d(160, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv10): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (conv11): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "UzoeaBAh4VeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 16  # Total epochs (8 with lr=0.001, then 8 with lr=0.0001)\n",
        "iteration = 55"
      ],
      "metadata": {
        "id": "Bo-29fjW6ch3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, device):\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
        "\n",
        "    loss_history = []  # Store loss per epoch\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch == 8:  # Reduce learning rate after first 8 epochs\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = 0.0001\n",
        "\n",
        "        model.train()  # Set model to training mode\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            if i >= iteration:  # Stop after the given number of iterations per epoch\n",
        "                break\n",
        "\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if (i + 1) % 10 == 0:  # Print every 10 iterations\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}], Iteration [{i+1}/{iteration}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = running_loss / iteration\n",
        "        loss_history.append(avg_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    print(\"Training finished!\")\n",
        "    plot_loss(loss_history)  # Call the loss plot function"
      ],
      "metadata": {
        "id": "R6YOSt-x5LPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load data\n",
        "train_loader = get_data_loader(batch_size=32)\n",
        "\n",
        "# train\n",
        "train_model(model, train_loader, device)"
      ],
      "metadata": {
        "id": "y8z58PeA2Hmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Locate Fovea**"
      ],
      "metadata": {
        "id": "u69X0B9mOHK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_kernel_2d(size=3, sigma=1.0):\n",
        "    \"\"\"Creates a 2D Gaussian kernel.\"\"\"\n",
        "    x = torch.arange(size) - size // 2\n",
        "    y = torch.arange(size) - size // 2\n",
        "    x, y = torch.meshgrid(x, y, indexing='ij')\n",
        "\n",
        "    kernel = torch.exp(-(x**2 + y**2) / (2 * sigma**2))\n",
        "    kernel /= kernel.sum()\n",
        "\n",
        "    return kernel\n",
        "\n",
        "\n",
        "def apply_gaussian_smoothing_2d(output, kernel_size=3, sigma=1.0):\n",
        "    \"\"\"Applies 2D Gaussian smoothing to each depth slice of a 3D network output.\"\"\"\n",
        "    kernel = gaussian_kernel_2d(kernel_size, sigma).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, H, W)\n",
        "\n",
        "    smoothed_slices = []\n",
        "    for d in range(output.shape[0]):  # Loop over depth\n",
        "        slice_2d = output[d].unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, H, W)\n",
        "        smoothed_slice = F.conv2d(slice_2d, kernel, padding=kernel_size // 2).squeeze(0).squeeze(0)\n",
        "        smoothed_slices.append(smoothed_slice)\n",
        "\n",
        "    return torch.stack(smoothed_slices)  # Shape: (D, H, W)\n",
        "\n",
        "def fill_max_probability_color(smoothed_output):\n",
        "    \"\"\"Finds the max probability location and highlights it on a 2D grayscale image.\"\"\"\n",
        "    # Convert 3D (D, H, W) tensor to 2D by taking max along depth\n",
        "    max_projection, max_depth = torch.max(smoothed_output, dim=0)  # Shape: (H, W)\n",
        "\n",
        "    # Get max probability location\n",
        "    max_idx = torch.argmax(max_projection)\n",
        "    max_y, max_x = np.unravel_index(max_idx.cpu().numpy(), max_projection.shape)\n",
        "\n",
        "    # Normalize grayscale image to 255 range\n",
        "    gray_image = (max_projection.cpu().numpy() * 255).astype(np.uint8)\n",
        "\n",
        "    # Convert grayscale to PIL image\n",
        "    img = Image.fromarray(gray_image, mode='L')  # 'L' for grayscale\n",
        "\n",
        "    # Highlight the max probability pixel with red\n",
        "    img_colored = img.convert(\"RGB\")  # Convert grayscale to RGB\n",
        "    pixels = img_colored.load()\n",
        "    pixels[max_x, max_y] = (255, 0, 0)  # Set max prob pixel to red\n",
        "\n",
        "    return img_colored, (max_x, max_y, max_depth[max_y, max_x].item())\n",
        "\n",
        "def process_output(output, kernel_size=3, sigma=1.0):\n",
        "    \"\"\"Applies 2D Gaussian smoothing and marks the highest probability pixel.\"\"\"\n",
        "    smoothed_output = apply_gaussian_smoothing_2d(output, kernel_size, sigma)\n",
        "    color_image, max_pos = fill_max_probability_color(smoothed_output)\n",
        "\n",
        "    return color_image, max_pos\n",
        "\n",
        "def show_image(image):\n",
        "    \"\"\"Displays an image using PIL.\"\"\"\n",
        "    image.show()"
      ],
      "metadata": {
        "id": "64Cs0aemNJo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "output = torch.rand(5, 5, 5)  # Example grayscale output tensor\n",
        "color_img, max_position = process_output(output, kernel_size=1, sigma=1.0)\n",
        "\n",
        "print(\"Max Probability Position:\", max_position)\n",
        "show_image(color_img)  # Show the result using PIL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb_mACDVNXpF",
        "outputId": "0f66dc6d-14f1-4b49-c2a0-282fd41320e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Probability Position: (2, 4, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1LHdDWZ_QvzE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}