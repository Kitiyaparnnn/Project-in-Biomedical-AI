{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f7f63f-35d8-4c02-9a40-fb5b7a94e4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aravjain/miniforge3/envs/spark_env/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/aravjain/miniforge3/envs/spark_env/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <FB2FD416-6C4D-3621-B677-61F07C02A3C5> /Users/aravjain/miniforge3/envs/spark_env/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Library/Frameworks/SentechSDK.framework/Versions/A/Libraries/libjpeg.9.dylib' (no such file), '/Library/Frameworks/SentechSDK.framework/Versions/A/Libraries/libjpeg.9.dylib' (no such file), '/libjpeg.9.dylib' (no such file), '/Users/aravjain/miniforge3/envs/spark_env/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/aravjain/miniforge3/envs/spark_env/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/aravjain/miniforge3/envs/spark_env/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/aravjain/miniforge3/envs/spark_env/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "from scipy.ndimage import gaussian_filter1d, gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e603aa66-52ae-4223-805b-089b6ba22828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"best_VGG_model_1.pth\"  # Update with your model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe8d23e-0d31-4831-80c3-856190151001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16BinaryClassifier(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(VGG16BinaryClassifier, self).__init__()\n",
    "        self.vgg16 = models.vgg16(pretrained=pretrained)\n",
    "        for param in self.vgg16.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.vgg16.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg16(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f39bed6-e8de-4e2b-a015-bdfa1f721a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OcclusionSensitivity:\n",
    "    def __init__(self, model, window_size=32, stride=16):\n",
    "        self.model = model\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    def generate_heatmap(self, input_tensor, target_class=None):\n",
    "        \"\"\"Generate occlusion sensitivity heatmap\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Original prediction\n",
    "            original_output = torch.sigmoid(self.model(input_tensor))\n",
    "            original_prob = original_output.item()\n",
    "            original_class = 1 if original_prob > 0.5 else 0\n",
    "            target_class = target_class or original_class\n",
    "            \n",
    "            # Setup dimensions\n",
    "            b, c, h, w = input_tensor.shape\n",
    "            heatmap = torch.zeros((h, w), device=device)\n",
    "            pad = self.window_size // 2\n",
    "            \n",
    "            # Pad input for complete coverage\n",
    "            padded_input = F.pad(input_tensor, (pad, pad, pad, pad), value=0)\n",
    "            \n",
    "            # Slide occlusion window\n",
    "            for y in tqdm(range(0, h, self.stride), desc=\"Generating occlusion map\"):\n",
    "                for x in range(0, w, self.stride):\n",
    "                    # Create occluded version\n",
    "                    occluded = padded_input.clone()\n",
    "                    y_start = y + pad\n",
    "                    x_start = x + pad\n",
    "                    occluded[..., y_start:y_start+self.window_size, \n",
    "                            x_start:x_start+self.window_size] = 0\n",
    "                    \n",
    "                    # Get modified prediction\n",
    "                    output = torch.sigmoid(self.model(occluded[..., pad:-pad, pad:-pad]))\n",
    "                    current_prob = output.item()\n",
    "                    \n",
    "                    # Calculate impact score\n",
    "                    if target_class == 1:\n",
    "                        score = original_prob - current_prob\n",
    "                    else:\n",
    "                        score = current_prob - original_prob\n",
    "                    \n",
    "                    # Update heatmap\n",
    "                    y_end = min(y + self.stride, h)\n",
    "                    x_end = min(x + self.stride, w)\n",
    "                    heatmap[y:y_end, x:x_end] += score\n",
    "            \n",
    "            # Normalize and return\n",
    "            heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
    "            return heatmap.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be789aca-eb24-45e9-8f76-05254f8db9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, device):\n",
    "    model = VGG16BinaryClassifier(pretrained=True)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device).eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb9177ae-bcae-443d-9070-3fc85bc3ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a directory of B-scans with occlusion sensitivity\n",
    "def process_bscans_with_occlusion(model, bscan_dir, output_dir, transform, window_size=32, stride=16):\n",
    "    \"\"\"\n",
    "    Process all B-scan images in a directory with occlusion sensitivity and save results\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        bscan_dir: Directory containing B-scan images\n",
    "        output_dir: Directory to save occlusion heatmaps\n",
    "        transform: Image transformation for model input\n",
    "        window_size: Size of occlusion window\n",
    "        stride: Stride for occlusion analysis\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create occlusion sensitivity analyzer\n",
    "    occluder = OcclusionSensitivity(model, window_size=window_size, stride=stride)\n",
    "    \n",
    "    # Get list of images\n",
    "    img_filenames = sorted([\n",
    "        f for f in os.listdir(bscan_dir)\n",
    "        if f.endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    ])\n",
    "    \n",
    "    for img_name in tqdm(img_filenames, desc=\"Processing B-scans\"):\n",
    "        img_path = os.path.join(bscan_dir, img_name)\n",
    "        \n",
    "        # Load and process image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Generate heatmap\n",
    "        heatmap = occluder.generate_heatmap(input_tensor)\n",
    "        \n",
    "        # Process visualizations\n",
    "        image_np = np.array(image)\n",
    "        heatmap_resized = cv2.resize(heatmap, (image_np.shape[1], image_np.shape[0]))\n",
    "        \n",
    "        # Create heatmap overlay\n",
    "        heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_INFERNO)\n",
    "        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Blend with original image\n",
    "        blended = cv2.addWeighted(image_np, 0.7, heatmap_colored, 0.3, 0)\n",
    "        \n",
    "        # Save results\n",
    "        output_path = os.path.join(output_dir, img_name)\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(blended, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # Save raw heatmap for further processing\n",
    "        heatmap_path = os.path.join(output_dir, f\"heatmap_{img_name}\")\n",
    "        cv2.imwrite(heatmap_path, np.uint8(255 * heatmap_resized))\n",
    "    \n",
    "    print(f\"âœ… Processed {len(img_filenames)} B-scans with occlusion sensitivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da25122-e6ed-4796-af5a-7baa8091d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Configuration\n",
    "    model_path = \"best_VGG_model_1.pth\"\n",
    "    bscan_dir = \"img\"  # Directory containing B-scan images\n",
    "    occlusions_output_dir = \"img_masked_img\"  # Directory to save occlusion heatmaps\n",
    "    enface_path = \"enface.jpg\"  # Path to the enface image\n",
    "    \n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load model\n",
    "    model = load_model(model_path, device)\n",
    "    \n",
    "    # Process B-scans with occlusion sensitivity\n",
    "    process_bscans_with_occlusion(\n",
    "        model=model,\n",
    "        bscan_dir=bscan_dir,\n",
    "        output_dir=occlusions_output_dir,\n",
    "        transform=transform,\n",
    "        window_size=32,\n",
    "        stride=16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f54e786a-7483-4f13-9383-a91759d12933",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
