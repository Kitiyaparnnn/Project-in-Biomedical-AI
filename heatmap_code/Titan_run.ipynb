{
 "cells": [
  {
   "cell_type": "code",
   "id": "f507c9a3-a62a-4989-b55c-e0e1d50e4f6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:32.490399Z",
     "start_time": "2025-05-05T20:10:32.486812Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "from scipy.ndimage import gaussian_filter1d, gaussian_filter"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "60c75fda-7a81-43c5-895b-7a32807ee588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:32.597763Z",
     "start_time": "2025-05-05T20:10:32.595332Z"
    }
   },
   "source": [
    "# Configuration\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = \"best_VGG_model_1.pth\"  # Update with your model path"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "d9dfeb7b-fff3-4efd-941c-9baf5c316ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:32.687963Z",
     "start_time": "2025-05-05T20:10:32.642714Z"
    }
   },
   "source": [
    "class VGG16BinaryClassifier(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(VGG16BinaryClassifier, self).__init__()\n",
    "        self.vgg16 = models.vgg16(pretrained=pretrained)\n",
    "        for param in self.vgg16.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.vgg16.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vgg16(x)"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "93ec358d-5c96-4271-9d10-f57ca21db157",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:32.777092Z",
     "start_time": "2025-05-05T20:10:32.700438Z"
    }
   },
   "source": [
    "class OcclusionSensitivity:\n",
    "    def __init__(self, model, window_size=32, stride=16):\n",
    "        self.model = model\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    def generate_heatmap(self, input_tensor, target_class=None):\n",
    "        \"\"\"Generate occlusion sensitivity heatmap\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Original prediction\n",
    "            original_output = torch.sigmoid(self.model(input_tensor))\n",
    "            original_prob = original_output.item()\n",
    "            original_class = 1 if original_prob > 0.5 else 0\n",
    "            target_class = target_class or original_class\n",
    "            \n",
    "            # Setup dimensions\n",
    "            b, c, h, w = input_tensor.shape\n",
    "            heatmap = torch.zeros((h, w), device=device)\n",
    "            pad = self.window_size // 2\n",
    "            \n",
    "            # Pad input for complete coverage\n",
    "            padded_input = F.pad(input_tensor, (pad, pad, pad, pad), value=0)\n",
    "            \n",
    "            # Slide occlusion window\n",
    "            for y in tqdm(range(0, h, self.stride), desc=\"Generating occlusion map\"):\n",
    "                for x in range(0, w, self.stride):\n",
    "                    # Create occluded version\n",
    "                    occluded = padded_input.clone()\n",
    "                    y_start = y + pad\n",
    "                    x_start = x + pad\n",
    "                    occluded[..., y_start:y_start+self.window_size, \n",
    "                            x_start:x_start+self.window_size] = 0\n",
    "                    \n",
    "                    # Get modified prediction\n",
    "                    output = torch.sigmoid(self.model(occluded[..., pad:-pad, pad:-pad]))\n",
    "                    current_prob = output.item()\n",
    "                    \n",
    "                    # Calculate impact score\n",
    "                    if target_class == 1:\n",
    "                        score = original_prob - current_prob\n",
    "                    else:\n",
    "                        score = current_prob - original_prob\n",
    "                    \n",
    "                    # Update heatmap\n",
    "                    y_end = min(y + self.stride, h)\n",
    "                    x_end = min(x + self.stride, w)\n",
    "                    heatmap[y:y_end, x:x_end] += score\n",
    "            \n",
    "            # Normalize and return\n",
    "            heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
    "            return heatmap.cpu().numpy()"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "f92f2a19-3d17-44d9-a31b-f36f44615445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:32.885269Z",
     "start_time": "2025-05-05T20:10:32.784315Z"
    }
   },
   "source": [
    "def load_model(model_path, device):\n",
    "    model = VGG16BinaryClassifier(pretrained=True)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device).eval()\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "f27a9d0d-a39e-4f88-b766-47c841859a01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:32.955003Z",
     "start_time": "2025-05-05T20:10:32.892532Z"
    }
   },
   "source": [
    "def visualize_occlusion(model, image_path, transform, window_size=32, stride=16):\n",
    "    # Load and process image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Generate heatmap\n",
    "    occlude = OcclusionSensitivity(model, window_size=window_size, stride=stride)\n",
    "    heatmap = occlude.generate_heatmap(input_tensor)\n",
    "    \n",
    "    # Process visualizations\n",
    "    image_np = np.array(image)\n",
    "    heatmap = cv2.resize(heatmap, image.size)\n",
    "    \n",
    "    # Create heatmap overlay\n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_INFERNO)\n",
    "    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Blend with original image\n",
    "    blended = cv2.addWeighted(image_np, 0.7, heatmap_colored, 0.3, 0)\n",
    "    \n",
    "    return image, heatmap, heatmap_colored, blended"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "9423405b-4dde-4389-94d2-d50b7c7c82f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:33.030952Z",
     "start_time": "2025-05-05T20:10:32.972004Z"
    }
   },
   "source": [
    "def visualize_multiple_occlusion(model, image_paths, transform, num_images=5, figsize=(20, 15), window_size=32, stride=16):\n",
    "    results = []\n",
    "    for img_path in image_paths[:num_images]:\n",
    "        results.append(visualize_occlusion(model, img_path, transform, window_size, stride=16))\n",
    "    \n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(num_images, 4, figsize=figsize)\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.2)\n",
    "    \n",
    "    for idx, (image, heatmap, heatmap_colored, blended) in enumerate(results):\n",
    "        axes[idx, 0].imshow(image)\n",
    "        axes[idx, 0].set_title(f\"Original {idx+1}\")\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        axes[idx, 1].imshow(heatmap, cmap='inferno')\n",
    "        axes[idx, 1].set_title(f\"Heatmap {idx+1}\")\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        axes[idx, 2].imshow(heatmap_colored)\n",
    "        axes[idx, 2].set_title(f\"Color Map {idx+1}\")\n",
    "        axes[idx, 2].axis('off')\n",
    "        \n",
    "        axes[idx, 3].imshow(blended)\n",
    "        axes[idx, 3].set_title(f\"Blended {idx+1}\")\n",
    "        axes[idx, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return results"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "id": "a6f11d95-6792-4c2d-9c16-ffcd85c9a5f6",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:33.228247Z",
     "start_time": "2025-05-05T20:10:33.041573Z"
    }
   },
   "source": [
    "# # Example Usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Load model\n",
    "#     model = load_model(MODEL_PATH, DEVICE)\n",
    "    \n",
    "#     # Define transforms\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((512, 512)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "    \n",
    "#     # Get sample images\n",
    "#     sample_images = [\n",
    "#         \"image1.jpg\",\n",
    "#         # \"image2.jpg\",\n",
    "#         # \"image3.jpg\",\n",
    "#         # \"image4.jpg\",\n",
    "#         # \"image5.jpg\"\n",
    "#         # Add your image paths here\n",
    "#     ]\n",
    "    \n",
    "#     # Generate visualizations\n",
    "#     results = visualize_multiple_occlusion(\n",
    "#         model=model,\n",
    "#         image_paths=sample_images,\n",
    "#         transform=transform,\n",
    "#         num_images=5,\n",
    "#         window_size=40,  # Adjust based on your image features\n",
    "#         stride=20\n",
    "#     )"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "12b99e34-1070-48f8-8639-6c7ee8e0d798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:33.237703Z",
     "start_time": "2025-05-05T20:10:33.236109Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f3aee0ad-7323-4a9a-a986-73d8d0653ae1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:33.305566Z",
     "start_time": "2025-05-05T20:10:33.282917Z"
    }
   },
   "source": [
    "# Process a directory of B-scans with occlusion sensitivity\n",
    "def process_bscans_with_occlusion(model, bscan_dir, output_dir, transform, window_size=32, stride=16):\n",
    "    \"\"\"\n",
    "    Process all B-scan images in a directory with occlusion sensitivity and save results\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model\n",
    "        bscan_dir: Directory containing B-scan images\n",
    "        output_dir: Directory to save occlusion heatmaps\n",
    "        transform: Image transformation for model input\n",
    "        window_size: Size of occlusion window\n",
    "        stride: Stride for occlusion analysis\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create occlusion sensitivity analyzer\n",
    "    occluder = OcclusionSensitivity(model, window_size=window_size, stride=stride)\n",
    "    \n",
    "    # Get list of images\n",
    "    img_filenames = sorted([\n",
    "        f for f in os.listdir(bscan_dir)\n",
    "        if f.endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    ])\n",
    "    \n",
    "    for img_name in tqdm(img_filenames, desc=\"Processing B-scans\"):\n",
    "        img_path = os.path.join(bscan_dir, img_name)\n",
    "        \n",
    "        # Load and process image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Generate heatmap\n",
    "        heatmap = occluder.generate_heatmap(input_tensor)\n",
    "        \n",
    "        # Process visualizations\n",
    "        image_np = np.array(image)\n",
    "        heatmap_resized = cv2.resize(heatmap, (image_np.shape[1], image_np.shape[0]))\n",
    "        \n",
    "        # Create heatmap overlay\n",
    "        heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_INFERNO)\n",
    "        heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Blend with original image\n",
    "        blended = cv2.addWeighted(image_np, 0.7, heatmap_colored, 0.3, 0)\n",
    "        \n",
    "        # Save results\n",
    "        output_path = os.path.join(output_dir, img_name)\n",
    "        cv2.imwrite(output_path, cv2.cvtColor(blended, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # Save raw heatmap for further processing\n",
    "        heatmap_path = os.path.join(output_dir, f\"heatmap_{img_name}\")\n",
    "        cv2.imwrite(heatmap_path, np.uint8(255 * heatmap_resized))\n",
    "    \n",
    "    print(f\"✅ Processed {len(img_filenames)} B-scans with occlusion sensitivity\")"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "751d5bda-47d6-43f8-951d-97914bab7519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:33.404966Z",
     "start_time": "2025-05-05T20:10:33.329188Z"
    }
   },
   "source": [
    "# Generate fovea probability map from occlusion heatmaps\n",
    "def generate_occlusion_fovea_map(enface_path, occlusions_dir, num_slices=128):\n",
    "    \"\"\"\n",
    "    Generate a fovea probability map from occlusion sensitivity heatmaps\n",
    "    \n",
    "    Args:\n",
    "        enface_path: Path to the enface image\n",
    "        occlusions_dir: Directory containing occlusion heatmap images\n",
    "        num_slices: Number of B-scan slices (default=128)\n",
    "        \n",
    "    Returns:\n",
    "        enface_img: Original enface image\n",
    "        prob_map: Generated probability map\n",
    "    \"\"\"\n",
    "    # Load enface image\n",
    "    enface_img = cv2.imread(enface_path)\n",
    "    enface_img = cv2.resize(enface_img, (512, 512))\n",
    "    \n",
    "    # Initialize heatmap canvas\n",
    "    prob_map = np.zeros((512, 512), dtype=np.float32)\n",
    "    y_positions = []\n",
    "    \n",
    "    # Read occlusion heatmap files\n",
    "    img_filenames = sorted([\n",
    "        f for f in os.listdir(occlusions_dir)\n",
    "        if f.startswith(\"1002\") and f.endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "    ])\n",
    "    \n",
    "    for img_name in img_filenames:\n",
    "        img_path = os.path.join(occlusions_dir, img_name)\n",
    "        heatmap_img = cv2.imread(img_path)\n",
    "        # heatmap_img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if heatmap_img is None:\n",
    "            continue\n",
    "            \n",
    "        # Extract index from filename\n",
    "        match = re.search(r'bscan_(\\d+)', img_name)\n",
    "        if not match:\n",
    "            continue\n",
    "            \n",
    "        idx = int(match.group(1))\n",
    "        y_pos = int((idx / num_slices) * 512)\n",
    "        y_positions.append(y_pos)\n",
    "        \n",
    "        # Resize and potentially roll (adjust shift if needed)\n",
    "        heatmap_img = cv2.resize(heatmap_img, (512, 512))\n",
    "        heatmap_img = np.roll(heatmap_img, shift=-4, axis=1)  # Same as ScoreCam implementation\n",
    "        \n",
    "        # Collapse vertically to horizontal profile\n",
    "        profile = np.sum(heatmap_img, axis=0).astype(np.float32)\n",
    "        profile = gaussian_filter1d(profile, sigma=2)  # Smooth profile\n",
    "        if profile.max() > 0:\n",
    "            profile /= profile.max()  # Normalize\n",
    "            \n",
    "        # Add profile to map at y_pos\n",
    "        prob_map[y_pos, :] = profile\n",
    "    \n",
    "    # Fill above & below missing lines with 0\n",
    "    if y_positions:\n",
    "        y_min, y_max = min(y_positions), max(y_positions)\n",
    "        for y in range(0, y_min):\n",
    "            prob_map[y, :] = 0.0\n",
    "        for y in range(y_max + 1, 512):\n",
    "            prob_map[y, :] = 0.0\n",
    "    \n",
    "    # Smooth vertically\n",
    "    prob_map = gaussian_filter(prob_map, sigma=(1.5, 1.5))\n",
    "    prob_map /= prob_map.max() + 1e-6  # Normalize\n",
    "    \n",
    "    return enface_img, prob_map"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "0525c6cc-4aed-4acc-8105-7ebd77e7fc67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:33.505363Z",
     "start_time": "2025-05-05T20:10:33.416932Z"
    }
   },
   "source": [
    "# Visualize the generated occlusion fovea map\n",
    "def visualize_occlusion_fovea_map(enface_img, prob_map, output_path=None):\n",
    "    \"\"\"\n",
    "    Visualize the generated occlusion fovea map\n",
    "    \n",
    "    Args:\n",
    "        enface_img: Original enface image\n",
    "        prob_map: Generated probability map\n",
    "        output_path: Path to save the visualization (optional)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(enface_img, cmap='gray')\n",
    "    heat = plt.imshow(prob_map, cmap='jet', alpha=0.5)\n",
    "    cbar = plt.colorbar(heat, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"Fovea Probability\", fontsize=12)\n",
    "    cbar.set_ticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✅ Saved visualization to {output_path}\")\n",
    "    \n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "26a9aa82-29ea-4c0f-86a1-8945c2a3efc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T20:10:33.589215Z",
     "start_time": "2025-05-05T20:10:33.514982Z"
    }
   },
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "# Main function to execute the pipeline\n",
    "def main():\n",
    "    # Configuration\n",
    "    model_path = \"best_VGG_model_1.pth\"\n",
    "    bscan_dir = \"Data\"  # Directory containing B-scan images\n",
    "    bscan_dir = os.path.join(bscan_dir, \"diseased_eye\", \"fovea_predictions\")\n",
    "\n",
    "    print(bscan_dir)\n",
    "     # Directory to save occlusion heatmaps\n",
    "    enface_path = \"enface.jpg\"  # Path to the enface image\n",
    "    # Define transforms\n",
    "    #\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    # Load model\n",
    "    model = load_model(model_path, device)\n",
    "    not_fovea = []\n",
    "\n",
    "    for category  in [\"Early\", \"GA\", \"Int\"]:\n",
    "\n",
    "        current_dir  = os.path.join(bscan_dir, category )\n",
    "        print(f\"\\nProcessing category: {category}\")\n",
    "        folders = [f for f in os.listdir(current_dir)\n",
    "                 if os.path.isdir(os.path.join(current_dir, f))]\n",
    "        for folder in folders:\n",
    "            try:\n",
    "                occlusions_output_dir = \"diseased_img_masked_img\"\n",
    "                folder_path = os.path.join(current_dir, folder)\n",
    "                folder_path = os.path.join(folder_path, \"fovea\")\n",
    "\n",
    "                occlusions_output_dir = os.path.join(occlusions_output_dir, category )\n",
    "                occlusions_output_dir = os.path.join(occlusions_output_dir, folder)\n",
    "\n",
    "                os.makedirs(occlusions_output_dir, exist_ok=True)\n",
    "                # Process B-scans with occlusion sensitivity\n",
    "                process_bscans_with_occlusion(\n",
    "                    model=model,\n",
    "                    bscan_dir=folder_path,\n",
    "                    output_dir=occlusions_output_dir,\n",
    "                    transform=transform,\n",
    "                    window_size=32,\n",
    "                    stride=16\n",
    "                )\n",
    "                source_folder = occlusions_output_dir\n",
    "                files_to_remove = glob.glob(os.path.join(source_folder, \"heatmap_*\"))\n",
    "                for file_path in files_to_remove:\n",
    "                    os.remove(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing category {category}: {str(e)}\")\n",
    "                not_fovea.append(category)\n",
    "\n",
    "    print(f\"Invalid directory count: {len(not_fovea)}\")\n",
    "    print(not_fovea)\n",
    "    # Generate and visualize fovea map\n",
    "    # enface_img, prob_map = generate_occlusion_fovea_map(\n",
    "    #     enface_path=enface_path,\n",
    "    #     occlusions_dir=occlusions_output_dir\n",
    "    # )\n",
    "    #\n",
    "    # # Visualize and save the result\n",
    "    # visualize_occlusion_fovea_map(\n",
    "    #     enface_img=enface_img,\n",
    "    #     prob_map=prob_map,\n",
    "    #     output_path=\"Occlusions_fovea_probability_map.png\"\n",
    "    # )"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "599461ac-5541-4671-944a-90ce5a85cf22",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-05T20:10:33.600423Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/diseased_eye/fovea_predictions\n",
      "\n",
      "Processing category: Early\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing B-scans:   0%|          | 0/13 [00:00<?, ?it/s]\n",
      "Generating occlusion map:   0%|          | 0/32 [00:00<?, ?it/s]\u001B[A\n",
      "Generating occlusion map:   3%|▎         | 1/32 [00:00<00:12,  2.57it/s]\u001B[A\n",
      "Generating occlusion map:   6%|▋         | 2/32 [00:00<00:11,  2.58it/s]\u001B[A\n",
      "Generating occlusion map:   9%|▉         | 3/32 [00:01<00:11,  2.59it/s]\u001B[A\n",
      "Generating occlusion map:  12%|█▎        | 4/32 [00:01<00:10,  2.60it/s]\u001B[A\n",
      "Generating occlusion map:  16%|█▌        | 5/32 [00:01<00:10,  2.60it/s]\u001B[A\n",
      "Generating occlusion map:  19%|█▉        | 6/32 [00:02<00:10,  2.56it/s]\u001B[A\n",
      "Generating occlusion map:  22%|██▏       | 7/32 [00:02<00:09,  2.55it/s]\u001B[A\n",
      "Generating occlusion map:  25%|██▌       | 8/32 [00:03<00:09,  2.58it/s]\u001B[A\n",
      "Generating occlusion map:  28%|██▊       | 9/32 [00:03<00:08,  2.58it/s]\u001B[A\n",
      "Generating occlusion map:  31%|███▏      | 10/32 [00:03<00:08,  2.55it/s]\u001B[A\n",
      "Generating occlusion map:  34%|███▍      | 11/32 [00:04<00:08,  2.55it/s]\u001B[A\n",
      "Generating occlusion map:  38%|███▊      | 12/32 [00:04<00:07,  2.53it/s]\u001B[A\n",
      "Generating occlusion map:  41%|████      | 13/32 [00:05<00:07,  2.50it/s]\u001B[A\n",
      "Generating occlusion map:  44%|████▍     | 14/32 [00:05<00:07,  2.51it/s]\u001B[A\n",
      "Generating occlusion map:  47%|████▋     | 15/32 [00:05<00:06,  2.52it/s]\u001B[A\n",
      "Generating occlusion map:  50%|█████     | 16/32 [00:06<00:06,  2.53it/s]\u001B[A\n",
      "Generating occlusion map:  53%|█████▎    | 17/32 [00:06<00:05,  2.53it/s]\u001B[A\n",
      "Generating occlusion map:  56%|█████▋    | 18/32 [00:07<00:05,  2.52it/s]\u001B[A\n",
      "Generating occlusion map:  59%|█████▉    | 19/32 [00:07<00:05,  2.50it/s]\u001B[A\n",
      "Generating occlusion map:  62%|██████▎   | 20/32 [00:07<00:04,  2.46it/s]\u001B[A\n",
      "Generating occlusion map:  66%|██████▌   | 21/32 [00:08<00:04,  2.47it/s]\u001B[A\n",
      "Generating occlusion map:  69%|██████▉   | 22/32 [00:08<00:04,  2.47it/s]\u001B[A"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62843794-1c3a-4e5b-8a72-e7c380c0a2a7",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from scipy.interpolate import griddata\n",
    "from tqdm import tqdm\n",
    "\n",
    "def map_bscan_heatmaps_to_enface(bscan_heatmaps, enface_image, pattern_type='foveal', \n",
    "                                 num_scans=None, smooth_factor=5, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Map B-scan heatmaps onto an enface image with thresholding to isolate bright regions\n",
    "    \n",
    "    Args:\n",
    "        bscan_heatmaps: List of numpy arrays containing heatmaps from OCT B-scans\n",
    "        enface_image: Numpy array of the enface image\n",
    "        pattern_type: The scan pattern - 'foveal', 'raster', or 'radial'\n",
    "        num_scans: Number of B-scans (if None, uses len(bscan_heatmaps))\n",
    "        smooth_factor: Size of Gaussian kernel for final smoothing\n",
    "        threshold: Value (0-1) to threshold the heatmap, only keeping values above this\n",
    "        \n",
    "    Returns:\n",
    "        The enface image with overlaid heatmap (only bright regions)\n",
    "    \"\"\"\n",
    "    # Make sure enface is RGB\n",
    "    if len(enface_image.shape) == 2:\n",
    "        enface_rgb = cv2.cvtColor(enface_image, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        enface_rgb = enface_image.copy()\n",
    "    \n",
    "    h, w = enface_rgb.shape[:2]\n",
    "    \n",
    "    # If num_scans not provided, use length of heatmaps\n",
    "    if num_scans is None:\n",
    "        num_scans = len(bscan_heatmaps)\n",
    "    \n",
    "    # Initialize points and values for interpolation\n",
    "    points = []\n",
    "    values = []\n",
    "    \n",
    "    # Generate scan coordinates based on pattern type\n",
    "    if pattern_type == 'foveal':\n",
    "        # Foveal scan pattern (all B-scans pass through center/fovea)\n",
    "        center_x, center_y = w // 2, h // 2\n",
    "        \n",
    "        # Distribute angles evenly\n",
    "        angles = np.linspace(0, np.pi, num_scans)  # 180 degrees coverage\n",
    "        \n",
    "        for i, angle in enumerate(angles):\n",
    "            if i >= len(bscan_heatmaps):\n",
    "                break\n",
    "                \n",
    "            heatmap = bscan_heatmaps[i]\n",
    "            \n",
    "            # Calculate line endpoints (line passing through center)\n",
    "            radius = min(w, h) // 2 - 5  # Slight margin from edge\n",
    "            \n",
    "            # Both ends of the line (passing through center)\n",
    "            x1 = int(center_x + radius * np.cos(angle))\n",
    "            y1 = int(center_y + radius * np.sin(angle))\n",
    "            x2 = int(center_x - radius * np.cos(angle))\n",
    "            y2 = int(center_y - radius * np.sin(angle))\n",
    "            \n",
    "            # Create the line\n",
    "            line_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            cv2.line(line_mask, (x1, y1), (x2, y2), 255, 1)\n",
    "            line_y, line_x = np.where(line_mask > 0)\n",
    "            \n",
    "            # Skip if no points\n",
    "            if len(line_x) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Resize heatmap to match line length\n",
    "            num_points = len(line_x)\n",
    "            resized_heatmap = cv2.resize(heatmap, (1, num_points), interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            # Add points and values\n",
    "            for j, (x, y) in enumerate(zip(line_x, line_y)):\n",
    "                if resized_heatmap[j, 0] > 0.05:  # Threshold for computation efficiency\n",
    "                    points.append([x, y])\n",
    "                    values.append(resized_heatmap[j, 0])\n",
    "    \n",
    "    # Add other pattern types as needed (raster, radial, etc.)\n",
    "    \n",
    "    # Create grid for interpolation\n",
    "    grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    \n",
    "    # Check if we have enough points for interpolation\n",
    "    if len(points) < 4:\n",
    "        print(\"Warning: Not enough points for interpolation. Check your heatmaps.\")\n",
    "        return enface_rgb\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    points = np.array(points)\n",
    "    values = np.array(values)\n",
    "    \n",
    "    # Interpolate values onto the grid\n",
    "    grid_z = griddata(points, values, (grid_x, grid_y), method='linear', fill_value=0)\n",
    "    \n",
    "    # Smooth the result\n",
    "    if smooth_factor > 0:\n",
    "        grid_z = cv2.GaussianBlur(grid_z, (smooth_factor, smooth_factor), 0)\n",
    "    \n",
    "    # Normalize the heatmap\n",
    "    grid_z = (grid_z - grid_z.min()) / (grid_z.max() - grid_z.min() + 1e-8)\n",
    "    \n",
    "    # Apply threshold to keep only bright regions\n",
    "    grid_z[grid_z < threshold] = 0\n",
    "    \n",
    "    # Optional: Renormalize after thresholding for better contrast\n",
    "    if np.max(grid_z) > 0:  # Check to avoid division by zero\n",
    "        grid_z = (grid_z - grid_z.min()) / (grid_z.max() - grid_z.min() + 1e-8)\n",
    "    \n",
    "    # Apply colormap to create colored heatmap\n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * grid_z), cv2.COLORMAP_HOT)\n",
    "    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create a mask for overlay (alpha channel)\n",
    "    alpha_mask = (grid_z > 0).astype(np.float32)\n",
    "    alpha_mask = cv2.GaussianBlur(alpha_mask, (5, 5), 0)  # Smooth the edges\n",
    "    \n",
    "    # Create result image\n",
    "    result = enface_rgb.copy()\n",
    "    \n",
    "    # Only blend where the mask is non-zero\n",
    "    for c in range(3):  # RGB channels\n",
    "        result[:,:,c] = enface_rgb[:,:,c] * (1 - alpha_mask) + heatmap_colored[:,:,c] * alpha_mask\n",
    "    \n",
    "    return result\n",
    "\n",
    "def process_enface_heatmap_with_threshold(heatmap_dir, enface_path, output_path=None, \n",
    "                                         pattern_type='foveal', smooth_factor=5, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Process enface image with thresholded heatmap overlay\n",
    "    \n",
    "    Args:\n",
    "        heatmap_dir: Directory containing heatmap images\n",
    "        enface_path: Path to the enface image\n",
    "        output_path: Path to save the result (optional)\n",
    "        pattern_type: Scan pattern type ('foveal', 'raster', 'radial')\n",
    "        smooth_factor: Size of Gaussian blur kernel for smoothing\n",
    "        threshold: Value (0-1) to threshold the heatmap, only showing bright regions\n",
    "        \n",
    "    Returns:\n",
    "        The resulting enface image with overlaid thresholded heatmap\n",
    "    \"\"\"\n",
    "    # Load heatmaps\n",
    "    heatmap_files = sorted([f for f in os.listdir(heatmap_dir) \n",
    "                          if f.startswith('heatmap_') or f.endswith('.png') or f.endswith('.jpg')])\n",
    "    \n",
    "    bscan_heatmaps = []\n",
    "    for heatmap_file in tqdm(heatmap_files, desc=\"Loading heatmaps\"):\n",
    "        path = os.path.join(heatmap_dir, heatmap_file)\n",
    "        heatmap = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if heatmap is None:\n",
    "            print(f\"Warning: Could not load {path}\")\n",
    "            continue\n",
    "            \n",
    "        # Normalize\n",
    "        heatmap = heatmap.astype(np.float32) / 255.0\n",
    "        bscan_heatmaps.append(heatmap)\n",
    "    \n",
    "    print(f\"Loaded {len(bscan_heatmaps)} heatmap images\")\n",
    "    \n",
    "    if len(bscan_heatmaps) == 0:\n",
    "        print(\"No heatmaps found. Check your directory.\")\n",
    "        return None\n",
    "    \n",
    "    # Load enface image\n",
    "    enface_image = cv2.imread(enface_path)\n",
    "    if enface_image is None:\n",
    "        print(f\"Could not load enface image: {enface_path}\")\n",
    "        return None\n",
    "        \n",
    "    enface_image = cv2.cvtColor(enface_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Map heatmaps to enface with threshold\n",
    "    result = map_bscan_heatmaps_to_enface(\n",
    "        bscan_heatmaps, \n",
    "        enface_image, \n",
    "        pattern_type=pattern_type, \n",
    "        smooth_factor=smooth_factor,\n",
    "        threshold=threshold\n",
    "    )\n",
    "    \n",
    "    # Save if output path provided\n",
    "    if output_path:\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # Make sure the file has a valid extension\n",
    "        valid_extensions = ['.png', '.jpg', '.jpeg', '.tiff', '.bmp']\n",
    "        file_ext = os.path.splitext(output_path)[1].lower()\n",
    "        \n",
    "        if file_ext not in valid_extensions:\n",
    "            # Default to PNG if extension is invalid\n",
    "            output_path = output_path + '.png'\n",
    "            print(f\"Added .png extension to output path: {output_path}\")\n",
    "            \n",
    "        cv2.imwrite(output_path, cv2.cvtColor(result, cv2.COLOR_RGB2BGR))\n",
    "        print(f\"Saved result to: {output_path}\")\n",
    "    \n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    # Configuration\n",
    "    model_path = \"best_VGG_model_1.pth\"\n",
    "    bscan_dir = os.path.join(\"Data\", \"diseased_eyes\")\n",
    "    print(f\"Base directory: {bscan_dir}\")\n",
    "\n",
    "    occlusions_output_dir = \"diseased_img_masked_img\"\n",
    "    enface_path = \"enface.jpg\"\n",
    "\n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Load model\n",
    "    model = load_model(model_path, device)\n",
    "\n",
    "    # Process each category\n",
    "    for category in [\"Early\", \"GA\", \"Int\"]:\n",
    "        current_dir = os.path.join(bscan_dir, category)\n",
    "        print(f\"\\nProcessing category: {category}\")\n",
    "\n",
    "        # Check if directory exists\n",
    "        if not os.path.exists(current_dir):\n",
    "            print(f\"Directory {current_dir} does not exist\")\n",
    "            continue\n",
    "\n",
    "        # List folders in current directory\n",
    "        folders = [f for f in os.listdir(current_dir)\n",
    "                   if os.path.isdir(os.path.join(current_dir, f))]\n",
    "\n",
    "        print(f\"Found {len(folders)} subdirectories:\")\n",
    "        for folder in folders:\n",
    "            print(f\" - {folder}\")\n",
    "\n",
    "        # Create output directory\n",
    "        category_output_dir = os.path.join(occlusions_output_dir, category)\n",
    "        os.makedirs(category_output_dir, exist_ok=True)\n",
    "\n",
    "        # Process B-scans\n",
    "        process_bscans_with_occlusion(\n",
    "            model=model,\n",
    "            bscan_dir=current_dir,\n",
    "            output_dir=category_output_dir,\n",
    "            transform=transform,\n",
    "            window_size=32,\n",
    "            stride=16\n",
    "        )\n",
    "\n",
    "    # Visualization code would follow...\n"
   ],
   "id": "e1d00c5196f670f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f32f4b4-2700-42e2-82e3-9a40c0b6c278",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26c4f5c6-c634-4c90-b43f-aeaf180d69d6",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
